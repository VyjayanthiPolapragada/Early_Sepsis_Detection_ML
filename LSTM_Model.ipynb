{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d683da18-1191-4686-b4a4-cf8fb4e925b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b863137f-9318-4d5b-9bcc-64e1b5c35f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define the LSTM model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer_size, num_classes):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size, batch_first=True)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_layer_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Get LSTM outputs\n",
    "        lstm_out, (hn, cn) = self.lstm(x)\n",
    "        \n",
    "        # Use the last time step's output for classification\n",
    "        out = self.fc(hn[-1])\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6239937e-1d2b-4ebf-bf20-9bebb7753963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Data preprocessing and reshaping (make sure your data is preprocessed)\n",
    "def preprocess_data(df):\n",
    "    \n",
    "    # Drop non-numeric or ID columns\n",
    "    X = data.drop(columns=['SepsisLabel', 'patient_id'])\n",
    "\n",
    "    # Target variable\n",
    "    y = data['SepsisLabel']\n",
    "\n",
    "    # Normalize the features\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    # Convert data into sequences (for LSTM input)\n",
    "    sequence_length = 10  # You can adjust this based on your needs\n",
    "    X_seq = []\n",
    "    y_seq = []\n",
    "    \n",
    "    for i in range(len(X) - sequence_length):\n",
    "        X_seq.append(X[i:i+sequence_length])\n",
    "        y_seq.append(y[i+sequence_length])\n",
    "\n",
    "    X_seq = np.array(X_seq)\n",
    "    y_seq = np.array(y_seq)\n",
    "    \n",
    "    return X_seq, y_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0568655-8583-4b7e-b4bf-2f334540e280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Train and evaluate the LSTM model\n",
    "def train_evaluate_lstm(X_train, y_train, X_test, y_test, input_size, hidden_layer_size=64, num_epochs=10, batch_size=64,model_name='LSTM_Model'):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Define the model, loss function, and optimizer\n",
    "    model = LSTMModel(input_size=input_size, hidden_layer_size=hidden_layer_size, num_classes=2).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()  # For binary classification\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Convert to torch tensors\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for i in range(0, len(X_train), batch_size):\n",
    "            # Get the batch data\n",
    "            X_batch = X_train_tensor[i:i+batch_size]\n",
    "            y_batch = y_train_tensor[i:i+batch_size]\n",
    "            \n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            output = model(X_batch)\n",
    "            \n",
    "            # Compute the loss\n",
    "            loss = criterion(output, y_batch)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(X_train):.4f}')\n",
    "    \n",
    "    # Evaluate the model on the test set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(X_test_tensor)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        y_pred = predicted.cpu().numpy()\n",
    "        y_true = y_test_tensor.cpu().numpy()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        auc = roc_auc_score(y_true, y_pred)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "        tpr = tp / (tp + fn) if (tp + fn) else 0\n",
    "        fpr = fp / (fp + tn) if (fp + tn) else 0\n",
    "        \n",
    "        # Print evaluation metrics\n",
    "        print(f'Accuracy: {acc:.4f}')\n",
    "        print(f'AUC: {auc:.4f}')\n",
    "        print(f'Confusion Matrix: \\n{tn} {fp}\\n{fn} {tp}')\n",
    "\n",
    "        #Store the results in a dictionary\n",
    "        results = {\n",
    "        \"model\": model_name,\n",
    "        \"Accuracy\": acc,\n",
    "        \"TPR (Recall)\": tpr,\n",
    "        \"FPR\": fpr,\n",
    "        \"AUC\": auc\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e33922e-5b4f-48e8-aff4-f91f8cf94ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess the data\n",
    "data=pd.read_csv('sepsis_data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5953fad4-cbb5-4631-98d4-0dc8f560cdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seq, y_seq = preprocess_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee6d4481-36bc-41e0-aae9-841bd1b17f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc290031-d7c3-48d8-ad43-47aba77acef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.0013\n",
      "Epoch 2/10, Loss: 0.0012\n",
      "Epoch 3/10, Loss: 0.0012\n",
      "Epoch 4/10, Loss: 0.0012\n",
      "Epoch 5/10, Loss: 0.0011\n",
      "Epoch 6/10, Loss: 0.0011\n",
      "Epoch 7/10, Loss: 0.0011\n",
      "Epoch 8/10, Loss: 0.0010\n",
      "Epoch 9/10, Loss: 0.0010\n",
      "Epoch 10/10, Loss: 0.0010\n",
      "Accuracy: 0.9835\n",
      "AUC: 0.5467\n",
      "Confusion Matrix: \n",
      "91374 126\n",
      "1414 148\n"
     ]
    }
   ],
   "source": [
    "input_size = X_train.shape[2]  # Number of features per time step\n",
    "lstm_imbalanced_results = train_evaluate_lstm(X_train, y_train, X_test, y_test, input_size, model_name='LSTM_Imbalanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ab51a99-8da4-426b-b315-ff9c6a8579e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM with weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d8543af-053d-43f2-ad43-184b174214c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Function to calculate class weights\n",
    "def calculate_class_weights(y_train):\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "    class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "    return class_weight_dict\n",
    "\n",
    "# Now modify the LSTM model training to incorporate these class weights\n",
    "def train_evaluate_lstm_with_weights(X_train, y_train, X_test, y_test, input_size, class_weight_dict, model_name=\"LSTM with Class Weights\"):\n",
    "    # Define the LSTM model as before\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
    "    model.add(LSTM(32, activation='relu', return_sequences=False))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Binary classification\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model with class weights\n",
    "    history = model.fit(X_train, y_train, epochs=10, batch_size=64, class_weight=class_weight_dict, verbose=1)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    # Calculate confusion matrix for TPR, FPR\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    tpr = tp / (tp + fn) if (tp + fn) else 0\n",
    "    fpr = fp / (fp + tn) if (fp + tn) else 0\n",
    "    \n",
    "    # Print evaluation metrics\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"AUC: {auc:.4f}\")\n",
    "    print(f\"Confusion Matrix: \\n{tn} {fp}\\n{fn} {tp}\")\n",
    "    \n",
    "    # Return results as a dictionary\n",
    "    results = {\n",
    "        \"model\": model_name,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"TPR (Recall)\": tpr,\n",
    "        \"FPR\": fpr,\n",
    "        \"AUC\": auc\n",
    "    }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88e6e97e-8464-4306-b8ee-0c157cc049ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m5817/5817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.7624 - loss: 0.6062\n",
      "Epoch 2/10\n",
      "\u001b[1m5817/5817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - accuracy: 0.7690 - loss: 0.5521\n",
      "Epoch 3/10\n",
      "\u001b[1m5817/5817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - accuracy: 0.7546 - loss: 0.5501\n",
      "Epoch 4/10\n",
      "\u001b[1m5817/5817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.7628 - loss: 0.5170\n",
      "Epoch 5/10\n",
      "\u001b[1m5817/5817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - accuracy: 0.7699 - loss: 0.4909\n",
      "Epoch 6/10\n",
      "\u001b[1m5817/5817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - accuracy: 0.7809 - loss: 0.4616\n",
      "Epoch 7/10\n",
      "\u001b[1m5817/5817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - accuracy: 0.7883 - loss: 0.4440\n",
      "Epoch 8/10\n",
      "\u001b[1m5817/5817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - accuracy: 0.8014 - loss: 0.4150\n",
      "Epoch 9/10\n",
      "\u001b[1m5817/5817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.8030 - loss: 0.3978\n",
      "Epoch 10/10\n",
      "\u001b[1m5817/5817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - accuracy: 0.8098 - loss: 0.3843\n",
      "\u001b[1m2909/2909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 846us/step\n",
      "Accuracy: 0.7601\n",
      "AUC: 0.7821\n",
      "Confusion Matrix: \n",
      "69484 22016\n",
      "305 1257\n"
     ]
    }
   ],
   "source": [
    "class_weight_dict = calculate_class_weights(y_train)\n",
    "\n",
    "# Train and evaluate with class weights\n",
    "lstm_with_weights_results = train_evaluate_lstm_with_weights(X_train, y_train, X_test, y_test, input_size, \n",
    "                                                             class_weight_dict, model_name=\"LSTM with Class Weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ed35810-292c-4c1e-9687-5be9ac2c4879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the results in a list or DataFrame\n",
    "results = []\n",
    "results.append(lstm_imbalanced_results)\n",
    "results.append(lstm_with_weights_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75af6eb3-8e2c-4668-b797-b2c7ed81a96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame for better visualization or saving\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d9296a1-4f8f-436d-973e-a1f5579b09f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>TPR (Recall)</th>\n",
       "      <th>FPR</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM_Imbalanced</td>\n",
       "      <td>0.983452</td>\n",
       "      <td>0.094750</td>\n",
       "      <td>0.001377</td>\n",
       "      <td>0.546687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LSTM with Class Weights</td>\n",
       "      <td>0.760149</td>\n",
       "      <td>0.804738</td>\n",
       "      <td>0.240612</td>\n",
       "      <td>0.782063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model  Accuracy  TPR (Recall)       FPR       AUC\n",
       "0          LSTM_Imbalanced  0.983452      0.094750  0.001377  0.546687\n",
       "1  LSTM with Class Weights  0.760149      0.804738  0.240612  0.782063"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "783ee31e-0f87-4734-9de3-a4a93e117527",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"lstm_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512dc4bf-bdfb-49f1-9089-9531a2c5f5f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
